{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1, week 1. Introduction:\n",
    "#Services vs. Safety in San Fransisco\n",
    "#I inted to investigate if neighborhood crime rates in San Fransisco are linked to the \n",
    "#various venues that are located in that neighborhood: as an example, if there are more \n",
    "#bars or nightclubs in the neighborhood, will there be more reported incidents? \n",
    "#This is relevant information for both landlords, sellers of real estate and families \n",
    "#with young kids, that are comparing different neighborhoods when relocating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2, week 1:\n",
    "#I will be using Foursquare location data of San Fransisco for the venue information in combination with the \n",
    "#San Fransico Police Department data (https://data.sfgov.org/Public-Safety/Map-of-Police-Department-Incident-Reports-2018-to-/jq29-s5wp), \n",
    "#both of these datasets shoud be up-to-date and are interlinked by latitude and longitude coordinates; both datasets have also a 'neighborhood'-field. As the SFPD database\n",
    "#is huge, I will be limiting the dataset to incidents reported between 1st Jan 2020 and 25th May 2020 or a shorter period if necessary (the Jan-May 2020\n",
    "#period is already big with 46,382 incidents). The Foursquare data is accessed via their developer site, and the SFPD data is available in CSV-format \n",
    "#from their home page mentioned earlier. \n",
    "#I intend to combine the datasets and cluster the data per neighborhood or per location, depending on which one is more parctical - the data amount is big, which I expect to be \n",
    "#a problem in practice. Thereafter I will compare the results: are there some neighborhoods with higher amount of crime incidents, and if so, are there more of some type\n",
    "#venues in those neighborhoods compared to other neighborhoods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # useful for many scientific computing in Python\n",
    "import pandas as pd # primary data structure library\n",
    "import folium\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "print('Folium installed and imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #Other tools if need be\n",
    "import pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#San Fransisco Police Department data downloaded from their site\n",
    "#df_data_0 becomes the mother of all incident data\n",
    "df_data_0 = pd.read_csv('Police_Department_Incident_Reports__2018_to_Present.csv')\n",
    "df_data_0.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning\n",
    "df_incidents=df_data_0\n",
    "df_incidents.dropna()\n",
    "df_incidents.drop(['Incident Datetime', 'Report Datetime', 'Incident Number', 'Row ID', 'Incident ID', 'CAD Number', 'Resolution', 'CNN', 'Supervisor District'], axis=1, inplace=True)\n",
    "df_incidents.rename(columns={'Latitude':'Y', 'Longitude':'X'}, inplace=True)\n",
    "df_incidents.rename(columns={'Incident Category':'IncidentCategory'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further cleaning, dropping incidents that have no coordinates or category\n",
    "df_incidents.dropna(subset = [\"X\"], inplace=True)\n",
    "df_incidents.dropna(subset = [\"IncidentCategory\"], inplace=True)\n",
    "df_incidents.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic statistics for future use\n",
    "#looking at which neighborhoods have the most incidents\n",
    "df_freq=df_incidents['Analysis Neighborhood'].value_counts().to_frame()\n",
    "df_freq.reset_index()\n",
    "df_freq.index.names = ['Neighborhood']\n",
    "df_freq.rename(columns={'Analysis Neighborhood':'Incidents'},inplace=True)\n",
    "df_freq.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving the neighborhoods lat & long coodrinates by taking the mean of the incident coordinates -> more realistic point when added to Foursquare data later on\n",
    "coordx=df_incidents.groupby('Analysis Neighborhood')['X'].mean() \n",
    "coordy=df_incidents.groupby('Analysis Neighborhood')['Y'].mean()\n",
    "coordy.reset_index()\n",
    "coordy.index.names = ['Neighborhood']\n",
    "coordy.reset_index()\n",
    "coordx.reset_index()\n",
    "coordx.index.names = ['Neighborhood']\n",
    "coordx.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerged=pd.merge(coordx, coordy, on='Neighborhood')\n",
    "dfmerged1=pd.merge(df_freq, dfmerged, on='Neighborhood')\n",
    "dfmerged1.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerged2=dfmerged1.reset_index()\n",
    "dfmerged2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents['IncidentCategory'].value_counts().to_frame() #what indicent type is the most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#incidents on map\n",
    "#San Francisco latitude and longitude values\n",
    "latitude = 37.77\n",
    "longitude = -122.42\n",
    "sanfran_map = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "sanfran_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a feature group for the incidents in the dataframe\n",
    "incidents = folium.map.FeatureGroup()\n",
    "\n",
    "# loop through the incidents and add each to the incidents feature group\n",
    "for lat, lng, in zip(df_incidents.Y, df_incidents.X):\n",
    "    incidents.add_child(\n",
    "        folium.features.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=5, # define how big you want the circle markers to be\n",
    "            color='yellow',\n",
    "            fill=True,\n",
    "            fill_color='blue',\n",
    "            fill_opacity=0.6\n",
    "        )\n",
    "    )\n",
    "sanfran_map.add_child(incidents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import plugins\n",
    "\n",
    "#the first map has too many incidents to be of use, clustering necessary for usability\n",
    "sanfran_map = folium.Map(location = [latitude, longitude], zoom_start = 12)\n",
    "\n",
    "# instantiate a mark cluster object for the incidents in the dataframe\n",
    "incidents = plugins.MarkerCluster().add_to(sanfran_map)\n",
    "\n",
    "# loop through the dataframe and add each data point to the mark cluster\n",
    "for lat, lng, label, in zip(df_incidents.Y, df_incidents.X, df_incidents.IncidentCategory):\n",
    "    folium.Marker(\n",
    "        location=[lat, lng],\n",
    "        icon=None,\n",
    "        popup=label,\n",
    "    ).add_to(incidents)\n",
    "\n",
    "# display map\n",
    "sanfran_map   #better, to be used in the presentation later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving on to Foursquare stuff - need a large dataset of venues, but if it proves too difficul to handle, then a smaller set will have to do. \n",
    "#more libraries\n",
    "import json \n",
    "!conda install -c conda-forge geopy --yes \n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'F1DSQIYSJRZYVLEU1DDSRFB0QPWDZQHCEQSGNEF3YWMM44SQ' # your Foursquare ID\n",
    "CLIENT_SECRET = 'QREISBS33NHTVRGIM3EIEUSPPA11I1K53HSH1HLHVOTFHK0Y' # your Foursquare Secret\n",
    "VERSION = '20180604'\n",
    "LIMIT = 30\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '3350 Mission St, San Francisco, USA'     #Safeway at Mission Street, seems to be quite an active place           \n",
    "geolocator = Nominatim(user_agent=\"SanFran_agent\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print(latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = 37.743217349999995 #might be unnecessary\n",
    "longitude = -122.42247150547838\n",
    "SanFrancisco_map = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "SanFrancisco_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lat, lng, neighborhood in zip(dfmerged2['Y'], dfmerged2['X'], dfmerged2['Neighborhood']):   #the neighborhoods on a map. Might be unnecessary\n",
    "    label = '{}'.format(neighborhood)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(SanFrancisco_map)  \n",
    "SanFrancisco_map    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_latitude = dfmerged2.loc[0, 'Y'] # neighborhood latitude value\n",
    "neighborhood_longitude = dfmerged2.loc[0, 'X'] # neighborhood longitude value\n",
    "\n",
    "neighborhood_name = dfmerged2.loc[0, 'Neighborhood'] # neighborhood name\n",
    "\n",
    "print('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n",
    "                                                               neighborhood_latitude, \n",
    "                                                               neighborhood_longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT=200\n",
    "radius=750\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    neighborhood_latitude, \n",
    "    neighborhood_longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(url).json()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = results['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues = json_normalize(venues) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)\n",
    "\n",
    "Mission_Venues = getNearbyVenues(names=dfmerged2['Neighborhood'],\n",
    "                                   latitudes=dfmerged2['Y'],\n",
    "                                   longitudes=dfmerged2['X']\n",
    "                                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mission_Venues.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} unique categories.'.format(len(Mission_Venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "Mission_onehot = pd.get_dummies(Mission_Venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "Mission_onehot['Neighborhood'] = Mission_Venues['Neighborhood'] \n",
    "\n",
    "# define a list of column names\n",
    "cols = Mission_onehot.columns.tolist()\n",
    "cols\n",
    "\n",
    "# move the column name to the beggining\n",
    "cols.insert(0, cols.pop(cols.index('Neighborhood')))\n",
    "cols\n",
    "\n",
    "#then use .reindex() function to reorder\n",
    "Mission_onehot = Mission_onehot.reindex(columns= cols)\n",
    "\n",
    "Mission_onehot.head(85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sanfran_grouped = Mission_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "Sanfran_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 20\n",
    "\n",
    "for hood in Sanfran_grouped['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = Sanfran_grouped[Sanfran_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sanfran_groupedcount = Mission_onehot.groupby('Neighborhood').sum().reset_index()\n",
    "Sanfran_groupedcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 20\n",
    "\n",
    "for hood in Sanfran_groupedcount['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = Sanfran_groupedcount[Sanfran_groupedcount['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks like the statistics would not point out to a larger amount of bars in Mission or Tenderloin. A closer look at the crime types on those areas might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neighborhoods_incidents=df_incidents[['Analysis Neighborhood', 'IncidentCategory']]\n",
    "df_neighborhoods_incidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=df_neighborhoods_incidents.groupby('Analysis Neighborhood')\n",
    "tool1=tool.get_group('Mission')\n",
    "tool1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=df_neighborhoods_incidents.groupby('Analysis Neighborhood')\n",
    "tool1=tool.get_group('Tenderloin')\n",
    "tool1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=df_neighborhoods_incidents.groupby('Analysis Neighborhood')\n",
    "tool1=tool.get_group('Western Addition')\n",
    "tool1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking closer at which incidents happens where with onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "Incident_onehot = pd.get_dummies(df_incidents[['IncidentCategory']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "Incident_onehot['Analysis Neighborhood'] = df_incidents['Analysis Neighborhood'] \n",
    "\n",
    "# define a list of column names\n",
    "cols1 = Incident_onehot.columns.tolist()\n",
    "cols1\n",
    "\n",
    "# move the column name to the beggining\n",
    "cols1.insert(0, cols1.pop(cols1.index('Analysis Neighborhood')))\n",
    "cols1\n",
    "\n",
    "#then use .reindex() function to reorder\n",
    "Incident_onehot = Incident_onehot.reindex(columns= cols1)\n",
    "\n",
    "Incident_onehot.head(85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incident_groupedmean = Incident_onehot.groupby('Analysis Neighborhood').mean().reset_index()\n",
    "Incident_groupedmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incident_groupedcount = Incident_onehot.groupby('Analysis Neighborhood').sum().reset_index()\n",
    "Incident_groupedcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_incidents = 20\n",
    "\n",
    "for hood in Incident_groupedmean['Analysis Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = Incident_groupedmean[Incident_groupedmean['Analysis Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['type','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_incidents = 20\n",
    "\n",
    "for hood in Incident_groupedcount['Analysis Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = Incident_groupedcount[Incident_groupedcount['Analysis Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['type','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_incidents))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incident_groupedcount.plot(kind='bar',x='Analysis Neighborhood',y='Other Offenses', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incident_groupedcount.plot(kind='bar',x='Analysis Neighborhood',y='Larceny Theft', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incident_groupedcount.plot(kind='bar',x='Analysis Neighborhood',y='Total', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
